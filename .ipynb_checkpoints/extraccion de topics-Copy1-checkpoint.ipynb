{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modelado de Topics\n",
    "\n",
    "El objetivo principal de este ejercicio es el de realizar un **análisis exploratorio** - etapa principal en cualquier problema de analítica, ML, DL y, por supuesto, NLP - de alguno de los datasets disponibles (tweets o reviews de Amazon).\n",
    "\n",
    "Además del análisis exploratorio, se pide que el alumno realice un **modelado de topics** identificando los principales temas que aparecen en los corpus, así como los tokens que los componen.\n",
    "\n",
    "Será muy valorable si se incluyen **gráficos descriptivos** que describan los corpus utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos lo que vayamos a necesitar\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- importar varios archivos\n",
    "- scar el reviewText y el overall(rating) y nuevo campo (clase o similar que seal del df archivo que viene\n",
    "- crear varias etiquetas para el rating\n",
    "    - biario: positivo negativo\n",
    "    - triario: positivo neutro negativo\n",
    "    - n-ario: 1 por clase (siento el ceil(n/2) el neutro)\n",
    "- combinar N documentos de cada dataset y un shufle\n",
    "- Preprocesar el conjunto y sacar el diccionario\n",
    "- sacar el LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con esta function extraeremos el df:\n",
    "#     - file_name: Nombre del archivo\n",
    "#     - main_category: Categoria principal para la clasificacion\n",
    "#     - limit: numero maximo de filas que tendra nuesto df\n",
    "def extract_df(file_name, main_category, limit = 10000):\n",
    "    data = pd.read_json(file_name, lines=True)\n",
    "    data = data [['reviewText', 'overall' , 'helpful']]  \n",
    "    data.rename(columns={\"reviewText\": \"review\", \"overall\": \"rating\"}, inplace=True)\n",
    "    data['category'] = main_category\n",
    "\n",
    "    # Procesamos el atributo helpful para que sea un numero\n",
    "    aux = np.zeros(len(data))\n",
    "    for i, it in enumerate(data['helpful']):\n",
    "        aux[i] = (0 if it[1] == 0 else it[0] / it[1])\n",
    "    data['helpful'] = aux\n",
    "    \n",
    "    index_list = np.array(data.index)\n",
    "    np.random.shuffle(np.reshape(index_list, (-1, 1)))\n",
    "    data = data.loc[index_list[:limit], :]\n",
    "    data.reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "files_to_read = [\n",
    "    { 'file_name': './datasets/reviews_CDs_and_Vinyl_5.json.gz', 'main_category': 'Music CD/Vinyl'},\n",
    "#     { 'file_name': './datasets/reviews_Electronics_5.json.gz', 'main_category': 'Electronics'},\n",
    "#     { 'file_name': './datasets/reviews_Movies_and_TV_5.json.gz', 'main_category': 'Movies/TV'},\n",
    "#     { 'file_name': './datasets/reviews_Musical_Instruments_5.json.gz', 'main_category': 'Musical instruments'}\n",
    "]\n",
    "\n",
    "\n",
    "frames = [ extract_df(**f) for f in files_to_read ]\n",
    "result = cudf.concat(frames)\n",
    "result\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = np.array(data.index)\n",
    "np.random.shuffle(np.reshape(index_list, (-1, 1)))\n",
    "shuffled_df = df.loc[index_list[:limit], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('./datasets/reviews_Musical_Instruments_5.json.gz', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos las reviews para sacar los topics de ellas y comprobamos si hay algun valor nolo\n",
    "reviews = data[['reviewText']]\n",
    "if reviews.isna().values.any():\n",
    "    reviews.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Original text:\\n{}\\n\\n'.format(reviews['reviewText'][0]))\n",
    "print('Processed text:\\n{}'.format(text_preprocessing(reviews['reviewText'][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_texts = []\n",
    "for text in reviews['reviewText'][:5000]:\n",
    "    processed_texts.append(text_preprocessing(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(processed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in processed_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(dictionary.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for it in corpus[0:1]:\n",
    "    for w, f in it:\n",
    "        print(dictionary[w], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 3\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    "    iterations=5,\n",
    "    passes=10,\n",
    "    alpha='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        \n",
    "        # Build LDA model\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                id2word=dictionary,\n",
    "                                                num_topics=num_topics)\n",
    "        \n",
    "        # Create a list of LDA models\n",
    "        model_list.append(model)\n",
    "        \n",
    "        # Compute the Coherence for each model\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ = 4\n",
    "end_ = 25\n",
    "step_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values = compute_coherence_values(\n",
    "    dictionary=dictionary,\n",
    "    corpus=corpus,\n",
    "    texts=processed_texts,\n",
    "    start=start_,\n",
    "    limit=end_,\n",
    "    step=step_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time()  - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_id = np.argmax(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = range(start_, end_, step_)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.axvline(optimal_id + start_, c='g', ls='--', alpha=0.8)\n",
    "plt.xlabel('Num Topics')\n",
    "plt.ylabel('Coherence score')\n",
    "plt.legend(('coherence_values'), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = model_list[optimal_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {};\n",
    "for i in range(len(optimal_model.get_topics())):\n",
    "    words = optimal_model.show_topic(i, topn = 20)\n",
    "    word_dict['Topic #' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
