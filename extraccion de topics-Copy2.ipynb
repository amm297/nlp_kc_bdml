{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modelado de Topics\n",
    "\n",
    "El objetivo principal de este ejercicio es el de realizar un **análisis exploratorio** - etapa principal en cualquier problema de analítica, ML, DL y, por supuesto, NLP - de alguno de los datasets disponibles (tweets o reviews de Amazon).\n",
    "\n",
    "Además del análisis exploratorio, se pide que el alumno realice un **modelado de topics** identificando los principales temas que aparecen en los corpus, así como los tokens que los componen.\n",
    "\n",
    "Será muy valorable si se incluyen **gráficos descriptivos** que describan los corpus utilizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.7/site-packages/nltk/decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "/home/alberto/anaconda3/lib/python3.7/site-packages/nltk/lm/counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "# Importamos lo que vayamos a necesitar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import string\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Nuestras funciones del archivo utils, para el procesado del texto\n",
    "from utils import file_to_dict, process_text\n",
    "\n",
    "# borrar\n",
    "from multiprocessing.pool import Pool\n",
    "from functools import partial\n",
    "from os import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extraccion y procesado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>helpful</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A fun way to bling up your desk and make sure ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Office products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I continue to love this show. Raylan and the r...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Amazon instant videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arrived in super flash time.  Like another rev...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Patio lawn/garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This treat ball works as expected. I used Temp...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Pet supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I know it's extrange but it works! It is easy ...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Baby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  helpful  \\\n",
       "0  A fun way to bling up your desk and make sure ...       4      1.0   \n",
       "1  I continue to love this show. Raylan and the r...       5      0.0   \n",
       "2  Arrived in super flash time.  Like another rev...       5      0.0   \n",
       "3  This treat ball works as expected. I used Temp...       4      0.5   \n",
       "4  I know it's extrange but it works! It is easy ...       4      0.0   \n",
       "\n",
       "                category  \n",
       "0        Office products  \n",
       "1  Amazon instant videos  \n",
       "2      Patio lawn/garden  \n",
       "3           Pet supplies  \n",
       "4                   Baby  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos la lista de las categorias que luego usaremos como número de topics\n",
    "categories = data['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Extraemos las reviews y las convertimos en una lista que posteriormente usaremos para entrenar nuestro modelo\n",
    "reviews = data[['review']]\n",
    "if reviews.isna().values.any():\n",
    "    reviews.dropna(inplace=True)\n",
    "reviews_list = reviews['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "lemas = file_to_dict('./datasets/lemmatization-en.txt')\n",
    "min_length = 50\n",
    "en_stop_words = gensim.parsing.preprocessing.STOPWORDS\n",
    "translate_table = dict((ord(char), None) for char in string.punctuation)  \n",
    "lang='en'\n",
    "stemmer = EnglishStemmer(ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para procesar el texto\n",
    "def process_text(min_length=50, lemas_dict={},translate_table={}, stop_words=[], lang='en', stemmer=None, review=None):\n",
    "    if not review or len(review) < min_length:\n",
    "        return None\n",
    "    \n",
    "    #Sustituimos si hay algun caracter &#DD\n",
    "    review = re.sub(r'(&#\\d+) | (&\\w+)', '', review)\n",
    "    \n",
    "    words = []\n",
    "    # Pocessamos nuestra review valida\n",
    "    for word in re.split(r'[;,.\\'\\s]\\s*', review):\n",
    "        # lematizamos\n",
    "        word = lemas_dict.get(word) or word\n",
    "        # stemmer\n",
    "        word = stemmer.stem(word) if stemmer else word\n",
    "        # Quitamos los signos de puntuacion\n",
    "        word = word.translate(translate_table)\n",
    "        # Comprobamos que tenga algun valor\n",
    "        # Comprobamos que tenga una longitud minima de 3 caracteres\n",
    "        # Comprobamos que no sea un stopword\n",
    "        if word and len(word) > 3 and word not in stop_words:\n",
    "            # Comprobamos si es un numero y lo sutituimos si tenemos el idioma\n",
    "            if lang and word.isdigit() :\n",
    "                word = num2words(word, lang=lang, ordinal=False)\n",
    "            # Añadimos a la lista\n",
    "            # La pasamos a minuscula\n",
    "            words.append(word.lower())\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    if type(row['review']) is str:    \n",
    "        aux = process_text(min_length, lemas, translate_table, en_stop_words, None, None, row['review'])\n",
    "        if aux:\n",
    "            return {\n",
    "                'review': ' '.join(aux),\n",
    "                'review_processed': aux,\n",
    "                'category': row['category']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.apply(lambda row: process_row(row), axis=1)\n",
    "df.dropna(inplace=True)\n",
    "df = pd.DataFrame(list(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>review_processed</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ways bling desks making surest ones guys wants...</td>\n",
       "      <td>[ways, bling, desks, making, surest, ones, guy...</td>\n",
       "      <td>Office products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continuing loving shows raylan rests character...</td>\n",
       "      <td>[continuing, loving, shows, raylan, rests, cha...</td>\n",
       "      <td>Amazon instant videos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrived super flashing timing like reviewers h...</td>\n",
       "      <td>[arrived, super, flashing, timing, like, revie...</td>\n",
       "      <td>Patio lawn/garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this treats balls works expected tempations ca...</td>\n",
       "      <td>[this, treats, balls, works, expected, tempati...</td>\n",
       "      <td>Pet supplies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knows extrange buts works easiest cleans eight...</td>\n",
       "      <td>[knows, extrange, buts, works, easiest, cleans...</td>\n",
       "      <td>Baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177121</th>\n",
       "      <td>second years happiest straps locks great products</td>\n",
       "      <td>[second, years, happiest, straps, locks, great...</td>\n",
       "      <td>Musical instruments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177122</th>\n",
       "      <td>this units says evens tried outs friends dodge...</td>\n",
       "      <td>[this, units, says, evens, tried, outs, friend...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177123</th>\n",
       "      <td>years smead hangings folders they plastics rem...</td>\n",
       "      <td>[years, smead, hangings, folders, they, plasti...</td>\n",
       "      <td>Office products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177124</th>\n",
       "      <td>pros dons needs touching deads looks cons silv...</td>\n",
       "      <td>[pros, dons, needs, touching, deads, looks, co...</td>\n",
       "      <td>Patio lawn/garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177125</th>\n",
       "      <td>bought went 2012 wrangler unlimited rubi backs...</td>\n",
       "      <td>[bought, went, 2012, wrangler, unlimited, rubi...</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177126 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  \\\n",
       "0       ways bling desks making surest ones guys wants...   \n",
       "1       continuing loving shows raylan rests character...   \n",
       "2       arrived super flashing timing like reviewers h...   \n",
       "3       this treats balls works expected tempations ca...   \n",
       "4       knows extrange buts works easiest cleans eight...   \n",
       "...                                                   ...   \n",
       "177121  second years happiest straps locks great products   \n",
       "177122  this units says evens tried outs friends dodge...   \n",
       "177123  years smead hangings folders they plastics rem...   \n",
       "177124  pros dons needs touching deads looks cons silv...   \n",
       "177125  bought went 2012 wrangler unlimited rubi backs...   \n",
       "\n",
       "                                         review_processed  \\\n",
       "0       [ways, bling, desks, making, surest, ones, guy...   \n",
       "1       [continuing, loving, shows, raylan, rests, cha...   \n",
       "2       [arrived, super, flashing, timing, like, revie...   \n",
       "3       [this, treats, balls, works, expected, tempati...   \n",
       "4       [knows, extrange, buts, works, easiest, cleans...   \n",
       "...                                                   ...   \n",
       "177121  [second, years, happiest, straps, locks, great...   \n",
       "177122  [this, units, says, evens, tried, outs, friend...   \n",
       "177123  [years, smead, hangings, folders, they, plasti...   \n",
       "177124  [pros, dons, needs, touching, deads, looks, co...   \n",
       "177125  [bought, went, 2012, wrangler, unlimited, rubi...   \n",
       "\n",
       "                     category  \n",
       "0             Office products  \n",
       "1       Amazon instant videos  \n",
       "2           Patio lawn/garden  \n",
       "3                Pet supplies  \n",
       "4                        Baby  \n",
       "...                       ...  \n",
       "177121    Musical instruments  \n",
       "177122             Automotive  \n",
       "177123        Office products  \n",
       "177124      Patio lawn/garden  \n",
       "177125             Automotive  \n",
       "\n",
       "[177126 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "<class 'tuple'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/alberto/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/alberto/anaconda3/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"<ipython-input-40-fe5ecfc3d1d4>\", line 3, in aux\n    print(pd.DataFrame.from_records(a))\n  File \"/home/alberto/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\", line 1636, in from_records\n    arrays, arr_columns = to_arrays(data, columns, coerce_float=coerce_float)\n  File \"/home/alberto/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\", line 484, in to_arrays\n    data = [tuple(x) for x in data]\n  File \"/home/alberto/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\", line 484, in <listcomp>\n    data = [tuple(x) for x in data]\nTypeError: 'int' object is not iterable\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-77b1735270b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "pool = Pool(cpu_count())\n",
    "\n",
    "res = [it for it in pool.map(aux, data.head(n=2).iterrows()) if it]\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(cpu_count())\n",
    "func = partial(process_text, min_length, {}, translate_table, en_stop_words, None, None)\n",
    "res = [it for it in pool.map(func, reviews_list) if it]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bling',\n",
       " 'desk',\n",
       " 'sure',\n",
       " 'want',\n",
       " 'steal',\n",
       " 'stapler',\n",
       " 'returning',\n",
       " 'immediately',\n",
       " 'stickers',\n",
       " 'stayed',\n",
       " 'offered',\n",
       " 'personalization',\n",
       " 'vibrant',\n",
       " 'great',\n",
       " 'teen',\n",
       " 'collegeaged',\n",
       " 'girl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Poner alguna grafica aqui que pinte datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequences = [(dictionary[w], f) for t in corpus for w, f in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(aux[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequences = [(w,f) for w,f in word_frequences if f > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w, f in most_frequences]\n",
    "freqs = [f for w, f in most_frequences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(' '.join(words))\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(words, freqs)\n",
    "plt.title('Bigram frequencies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extraccion de topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topics(corpus, dictionary, texts, num_topics):\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        iterations=5,\n",
    "        passes=10,\n",
    "        alpha='auto'\n",
    "    )\n",
    "    \n",
    "    coherence = CoherenceModel(\n",
    "        model=lda_model, \n",
    "        texts=texts, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v').get_coherence()\n",
    "    \n",
    "    perplexity = lda_model.log_perplexity(corpus)\n",
    "    \n",
    "    return lda_model, coherence, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_topics(lda_model, topn=20):\n",
    "    word_dict = {};\n",
    "    for i in range(len(lda_model.get_topics())):\n",
    "        words = lda_model.show_topic(i, topn = topn)\n",
    "        word_dict['Topic #' + '{:02d}'.format(i+1)] = [i[0] for i in words]\n",
    "    return pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pyLDAvis(lda_model, corpus, dictionary, export=False):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "    if export:\n",
    "        pyLDAvis.save_html(vis, f'./datasets/lda_model_vis_{len(lda_model.get_topics())}_topics.html')\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = len(categories)\n",
    "\n",
    "lda_model, coherence, perplexity = extract_topics(corpus, dictionary, res, num_topics)\n",
    "\n",
    "print(f\"Para el modelo con {num_topics} topics, tiene una coherecia de {coherence} y una perplejidad de {perplexity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Nuestras categorias iniciales son estas, vamos a ver como las comparamos con las extraidas del lda_model\n",
    "for i,c in enumerate(categories):\n",
    "    print(f\"Categoria {i}: {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "view_topics(lda_model, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observamos que podemos clasificar los topics de la siguiente manera:\n",
    "\n",
    "<span style=\"color:green\">**Topic#01** => </span> Al tener palabras como <span style=\"color:blue\">*songs*, *tracks*, *lyrics* </span>podemos definir que se corresponde con nuestra categoria de <span style=\"color:orange\">*Digital Music*</span>\n",
    "\n",
    "<span style=\"color:green\">**Topic#02** => </span> Al tener palabras como <span style=\"color:blue\">*taping*, *paper*, *printer* </span>podemos definir que se corresponde con nuestra categoria de <span style=\"color:orange\">*Office products*</span>\n",
    "\n",
    "<span style=\"color:green\">**Topic#03** => </span> Al tener palabras como <span style=\"color:blue\">*babies*, *cleans*, *seats*, *washing* </span>podemos definir que se corresponde con nuestra categoria de <span style=\"color:orange\">*Baby*</span>, a mi parecer puede ser por por productos para bebe que sean faciles de limpiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pyLDAvis(lda_model, corpus, dictionary, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 24\n",
    "\n",
    "lda_model_2, coherence_2, perplexity_2 = extract_topics(corpus, dictionary, res, num_topics)\n",
    "\n",
    "print(f\"Para el modelo con {num_topics} topics, tiene una coherecia de {coherence_2} y una perplejidad de {perplexity_2} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_topics(lda_model_2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pyLDAvis(lda_model_2, corpus, dictionary, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import EnglishStemmer\n",
    "stemmer = EnglishStemmer(ignore_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{0:15}{1:10}'.format('Token' ,'Stem'))\n",
    "for word in res[0]:\n",
    "    print('{0:15}{1:10}'.format(word, stemmer.stem(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
